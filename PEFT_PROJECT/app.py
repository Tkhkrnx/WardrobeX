# app.py
from contextlib import asynccontextmanager
from fastapi import FastAPI, File, UploadFile
from PIL import Image
import torch
from transformers import ViTImageProcessor, ViTModel, AutoModelForCausalLM, AutoTokenizer
from pymilvus import connections, Collection
import numpy as np
import io
import re
import cv2
import os
from ultralytics import YOLO
from typing import List, Dict
from peft import PeftModel
from langchain_openai import ChatOpenAI
import logging
from dotenv import load_dotenv

load_dotenv(override=True)
# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("app.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# åˆ›å»ºå®‰å…¨çš„æ—¥å¿—è®°å½•å‡½æ•°
def safe_log_info(message, *args, **kwargs):
    try:
        logger.info(message, *args, **kwargs)
    except UnicodeEncodeError:
        # å¤„ç†å¯èƒ½åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ¶ˆæ¯
        if isinstance(message, str):
            safe_message = message.encode('utf-8', errors='replace').decode('utf-8')
            logger.info(safe_message, *args, **kwargs)
        else:
            logger.info(message, *args, **kwargs)

app = FastAPI()

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨æ¨¡å‹
extractor = None
vit = None
coll = None
yolo_model = None
# æ–‡æ¡ˆç”Ÿæˆæ¨¡å‹ç›¸å…³
text_tokenizer = None
text_model = None
# å¼ºæ¨¡å‹APIé…ç½®
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = "https://www.chataiapi.com/v1"
LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "claude-3-5-sonnet-20241022")

class_names = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    load_models()
    yield
    # å…³é—­æ—¶æ‰§è¡Œï¼ˆå¦‚æœéœ€è¦ï¼‰

app = FastAPI(lifespan=lifespan)

def load_models():
    """
    åŠ è½½æ‰€æœ‰æ¨¡å‹
    """
    global extractor, vit, coll, yolo_model, text_tokenizer, text_model

    safe_log_info("Loading models...")

    # åŠ è½½ ViT ç‰¹å¾æå–å™¨
    extractor = ViTImageProcessor.from_pretrained('/data/google/vit-base-patch16-224')

    # åŠ è½½åŸºç¡€ ViT æ¨¡å‹ (ä½¿ç”¨8ä½é‡åŒ–)
    vit = ViTModel.from_pretrained('/data/google/vit-base-patch16-224',
                                   load_in_8bit=True,
                                   device_map="auto")

    # åŠ è½½ä½¿ç”¨ LoRA å¾®è°ƒçš„æœ€ä½³æ¨¡å‹æƒé‡
    try:
        if os.path.exists('outputs/vit_lora_best_peft') and os.path.isdir('outputs/vit_lora_best_peft'):
            config_file = os.path.join('outputs/vit_lora_best_peft', 'adapter_config.json')
            if os.path.exists(config_file):
                vit = PeftModel.from_pretrained(vit, 'outputs/vit_lora_best_peft')
                vit = vit.merge_and_unload()
                safe_log_info("LoRA model loaded successfully!")
            else:
                safe_log_info("LoRA config file not found, using base ViT model")
        else:
            safe_log_info("LoRA model directory not found, using base ViT model")
    except Exception as e:
        safe_log_info(f"Failed to load LoRA model: {e}")
    vit.eval()  # ç§»é™¤.cuda()ï¼Œåœ¨CPUä¸Šè¿è¡Œ

    # åŠ è½½æœ¬åœ°å¾®è°ƒçš„æ–‡æ¡ˆç”Ÿæˆæ¨¡å‹ (Prompt Tuning) ä½¿ç”¨8ä½é‡åŒ–
    try:
        safe_log_info("Loading fine-tuned text generation model...")
        base_model_name = '/data/Qwen3-0.6B'
        text_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)
        if text_tokenizer.pad_token is None:
            text_tokenizer.pad_token = text_tokenizer.eos_token

        # ä½¿ç”¨8ä½é‡åŒ–åŠ è½½æ¨¡å‹ä»¥èŠ‚çœå†…å­˜
        base_model = AutoModelForCausalLM.from_pretrained(
            base_model_name,
            trust_remote_code=True,
            load_in_8bit=True,  # ä½¿ç”¨8ä½é‡åŒ–
            device_map="auto",  # è‡ªåŠ¨è®¾å¤‡æ˜ å°„
            low_cpu_mem_usage=True  # å‡å°‘CPUå†…å­˜ä½¿ç”¨
        )

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è®­ç»ƒåæœ€å¥½çš„æ¨¡å‹
        best_model_path = 'outputs/qwen3_0.6b_prompt_best'
        final_model_path = 'outputs/qwen3_0.6b_prompt_final'

        if os.path.exists(best_model_path) and os.path.isdir(best_model_path):
            config_file = os.path.join(best_model_path, 'adapter_config.json')
            if os.path.exists(config_file):
                # åŠ è½½è®­ç»ƒåæœ€å¥½çš„æ¨¡å‹
                text_model = PeftModel.from_pretrained(base_model, best_model_path)
                text_model.eval()
                safe_log_info("Best Prompt Tuning model loaded successfully from qwen3_0.6b_prompt_best!")
            else:
                safe_log_info("Best Prompt Tuning config file not found, checking final model...")
                # æ£€æŸ¥æœ€ç»ˆæ¨¡å‹
                if os.path.exists(final_model_path) and os.path.isdir(final_model_path):
                    config_file = os.path.join(final_model_path, 'adapter_config.json')
                    if os.path.exists(config_file):
                        text_model = PeftModel.from_pretrained(base_model, final_model_path)
                        text_model.eval()
                        safe_log_info("Final Prompt Tuning model loaded successfully from qwen3_0.6b_prompt_final!")
                    else:
                        safe_log_info("Final Prompt Tuning config file not found, using base model")
                        text_model = base_model
                else:
                    safe_log_info("Prompt Tuning model directory not found, using base model")
                    text_model = base_model
        else:
            safe_log_info("Best Prompt Tuning model directory not found, checking final model...")
            # æ£€æŸ¥æœ€ç»ˆæ¨¡å‹
            if os.path.exists(final_model_path) and os.path.isdir(final_model_path):
                config_file = os.path.join(final_model_path, 'adapter_config.json')
                if os.path.exists(config_file):
                    text_model = PeftModel.from_pretrained(base_model, final_model_path)
                    text_model.eval()
                    safe_log_info("Final Prompt Tuning model loaded successfully from qwen3_0.6b_prompt_final!")
                else:
                    safe_log_info("Final Prompt Tuning config file not found, using base model")
                    text_model = base_model
            else:
                safe_log_info("Prompt Tuning model directory not found, using base model")
                text_model = base_model

        safe_log_info("Fine-tuned text generation model loaded successfully!")
    except Exception as e:
        safe_log_info(f"Failed to load fine-tuned text model: {e}")
        import traceback
        safe_log_info(traceback.format_exc())
        text_tokenizer = None
        text_model = None

    # è¿æ¥ Milvus
    try:
        connections.connect(host='150.158.55.76', port='19530')
        coll = Collection('fashion_features')
        coll.load()
        safe_log_info("Milvus connected successfully!")
    except Exception as e:
        safe_log_info(f"Failed to connect to Milvus: {e}")
        coll = None

    # åŠ è½½ YOLO æ¨¡å‹ç”¨äºæ£€æµ‹è¡£ç‰©ç±»å‹ï¼ˆå‡å°‘æ—¥å¿—è¾“å‡ºï¼‰
    try:
        yolo_model = YOLO('modanet_clothing_model.pt')
        # å‡å°‘YOLOæ¨¡å‹çš„æ—¥å¿—è¾“å‡º
        if hasattr(yolo_model, 'names') and yolo_model.names:
            class_names.update(yolo_model.names)
        else:
            class_names.update({
                0: 'top', 1: 'bottom', 2: 'dress', 3: 'outer', 4: 'pants',
                5: 'skirt', 6: 'headwear', 7: 'eyewear', 8: 'bag', 9: 'shoes',
                10: 'belt', 11: 'socks', 12: 'tights', 13: 'gloves', 14: 'scarf'
            })
        safe_log_info("YOLO model loaded successfully!")
    except Exception as e:
        safe_log_info(f"Failed to load YOLO model: {e}")
        yolo_model = None
        class_names.update({
            0: 'top', 1: 'bottom', 2: 'dress', 3: 'outer', 4: 'pants',
            5: 'skirt', 6: 'headwear', 7: 'eyewear', 8: 'bag', 9: 'shoes',
            10: 'belt', 11: 'socks', 12: 'tights', 13: 'gloves', 14: 'scarf'
        })

    safe_log_info("All models loaded successfully!")


def generate_outline_local(prompt: str, max_tokens: int = 100) -> str:
    """
    ä½¿ç”¨æœ¬åœ°å¾®è°ƒæ¨¡å‹ç”Ÿæˆæ­é…è¦ç‚¹
    """
    if text_tokenizer is None or text_model is None:
        return "æ–‡æ¡ˆç”Ÿæˆæ¨¡å‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„ã€‚"

    try:
        # å¯¹æç¤ºè¿›è¡Œé¢„å¤„ç†ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
        if not prompt.strip():
            return "è¾“å…¥æç¤ºä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆæ–‡æ¡ˆã€‚"

        # æ¸…ç†æç¤ºè¯ï¼Œç¡®ä¿æ²¡æœ‰å¤šä½™çš„ç©ºç™½å­—ç¬¦
        prompt = prompt.strip()

        # ä½¿ç”¨float16ç²¾åº¦å¹¶é¿å…ä½¿ç”¨GPU
        inputs = text_tokenizer(prompt, return_tensors='pt', padding=True, truncation=True, max_length=512)

        with torch.no_grad():
            outputs = text_model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                pad_token_id=text_tokenizer.pad_token_id,
                eos_token_id=text_tokenizer.eos_token_id,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1,
                length_penalty=1.0,
                no_repeat_ngram_size=3,
                early_stopping=True
            )
            text = text_tokenizer.decode(outputs[0], skip_special_tokens=True)
            # ç§»é™¤è¾“å…¥éƒ¨åˆ†ï¼Œåªè¿”å›ç”Ÿæˆçš„éƒ¨åˆ†
            generated_text = text[len(prompt):].strip()

        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦æœ‰æ•ˆ
        if not generated_text or len(generated_text) < 5:
            return "æ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„æ­é…è¦ç‚¹ï¼Œè¯·ç¨åé‡è¯•ã€‚"

        return generated_text
    except Exception as e:
        safe_log_info(f"Error generating outline with local model: {e}")
        import traceback
        safe_log_info(traceback.format_exc())
        return "ç”Ÿæˆæ­é…è¦ç‚¹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"




def call_qwen_api(prompt: str) -> str:
    """
    è°ƒç”¨APIç”Ÿæˆé«˜è´¨é‡æ–‡æ¡ˆ
    """
    if not LLM_API_KEY:
        return "APIå¯†é’¥æœªé…ç½®ï¼Œæ— æ³•è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ–‡æ¡ˆã€‚"

    try:
        llm = ChatOpenAI(
            temperature=0.7,
            model=LLM_MODEL_NAME,
            api_key=LLM_API_KEY,
            base_url=LLM_BASE_URL
        )

        response = llm.invoke(prompt)
        return response.content
    except Exception as e:
        safe_log_info(f"Error calling Qwen API: {e}")
        import traceback
        safe_log_info(traceback.format_exc())
        return "è°ƒç”¨å¤§æ¨¡å‹APIæ—¶å‡ºé”™ï¼Œè¯·ç¨åé‡è¯•ã€‚"


def detect_clothing_category(image: Image.Image) -> str:
    """
    ä½¿ç”¨YOLOæ¨¡å‹æ£€æµ‹è¡£ç‰©ç±»åˆ«
    """
    global class_names, yolo_model

    # å¦‚æœYOLOæ¨¡å‹æœªåŠ è½½ï¼Œç›´æ¥è¿”å›unknown
    if yolo_model is None:
        safe_log_info("YOLO model not loaded")
        return 'unknown'

    try:
        # å°†PILå›¾åƒè½¬æ¢ä¸ºOpenCVæ ¼å¼ï¼ˆåœ¨å†…å­˜ä¸­ï¼‰
        # å…ˆè½¬æ¢ä¸ºnumpyæ•°ç»„
        img_array = np.array(image)
        # RGBè½¬BGRï¼ˆPILä½¿ç”¨RGBï¼ŒOpenCVä½¿ç”¨BGRï¼‰
        cv_image = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

        safe_log_info(f"Input image size: {img_array.shape}")

        # ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œæ£€æµ‹ï¼Œå°è¯•ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼
        results = yolo_model.predict(source=cv_image, conf=0.1)  # è¿›ä¸€æ­¥é™ä½ç½®ä¿¡åº¦é˜ˆå€¼

        safe_log_info(f"Detection results: {results}")

        # è·å–æ£€æµ‹åˆ°çš„ç±»åˆ«
        for r in results:
            if hasattr(r, 'boxes') and r.boxes is not None and len(r.boxes) > 0:
                # æ‰“å°æ£€æµ‹åˆ°çš„æ‰€æœ‰æ¡†çš„ä¿¡æ¯
                confs = r.boxes.conf.cpu().numpy()
                classes = r.boxes.cls.cpu().numpy()

                safe_log_info(f"Detected boxes - confidences: {confs}, classes: {classes}")

                if len(confs) > 0:
                    # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œå–æœ€é«˜çš„
                    sorted_indices = np.argsort(confs)[::-1]  # é™åºæ’åˆ—
                    for idx in sorted_indices:
                        conf = confs[idx]
                        class_id = int(classes[idx])

                        safe_log_info(f"Checking detection - confidence: {conf}, class_id: {class_id}")

                        # ä½¿ç”¨å…¨å±€class_namesæ˜ å°„è·å–ç±»åˆ«åç§°
                        detected_class_name = class_names.get(class_id, 'unknown')
                        safe_log_info(f"Detected class name: {detected_class_name}")

                        # åªè¦ç½®ä¿¡åº¦å¤§äºä¸€å®šé˜ˆå€¼å°±è¿”å›
                        if conf > 0.05:  # éå¸¸ä½çš„é˜ˆå€¼
                            return detected_class_name

    except Exception as e:
        safe_log_info(f"Error in detect_clothing_category: {e}")
        import traceback
        safe_log_info(traceback.format_exc())

    safe_log_info("No valid detection found, returning 'unknown'")
    return 'unknown'


def extract_category_from_filename(filename: str) -> str:
    pattern = r'_([a-zA-Z]+)_crop_\d+\.'
    match = re.search(pattern, filename)
    return match.group(1).lower() if match else 'unknown'


def get_complementary_categories(input_category: str) -> List[str]:
    complementary_map = {
        'top': ['bottom', 'pants', 'skirt', 'shoes', 'bag'],
        'bottom': ['top', 'shoes', 'bag'],
        'pants': ['top', 'shoes', 'bag'],
        'skirt': ['top', 'shoes', 'bag'],
        'dress': ['shoes', 'bag', 'belt', 'outer'],  # ä¸ºdresså¢åŠ æ›´å¤šæ­é…é€‰é¡¹
        'outer': ['top', 'bottom', 'pants', 'skirt', 'shoes', 'bag'],
        'shoes': ['top', 'bottom', 'pants', 'skirt', 'dress'],
        'bag': ['top', 'bottom', 'pants', 'skirt', 'dress', 'shoes'],
        'headwear': ['top', 'dress'],
        'belt': ['pants', 'skirt', 'dress'],
        'unknown': ['top', 'bottom', 'pants', 'skirt', 'dress', 'shoes', 'bag', 'outer']
    }
    return complementary_map.get(input_category, ['top', 'bottom', 'shoes', 'bag'])


def search_items_by_category(category: str, input_embedding: np.ndarray, limit: int = 20) -> List[Dict]:
    if coll is None:
        return []
    try:
        search_results = coll.search(
            input_embedding,
            'embedding',
            param={"metric_type": "IP", "params": {"nprobe": 32}}, # è¿›ä¸€æ­¥é™ä½nprobe
            limit=limit,
            expr=f"category == '{category}'",
            output_fields=['image_name', 'color', 'shape', 'material']
        )
        items = []
        for result in search_results[0]:
            try:
                items.append({
                    "id": result.id,
                    "image_name": result.entity.image_name,
                    "category": category,
                    "color": getattr(result.entity, 'color', 'unknown'),
                    "shape": getattr(result.entity, 'shape', 'unknown'),
                    "material": getattr(result.entity, 'material', 'unknown'),
                    "distance": result.distance
                })
            except Exception as e:
                safe_log_info(f"Error processing search result: {e}")
                continue
        safe_log_info(f"Found {len(items)} items for category {category}")
        return items
    except Exception as e:
        safe_log_info(f"Error searching items by category {category}: {e}")
        return []


def get_complementary_items(input_category: str, input_embedding: np.ndarray,
                            input_color: str = 'unknown', input_shape: str = 'unknown',
                            input_material: str = 'unknown') -> Dict[str, Dict]:
    recommendations = {}
    complementary_categories = get_complementary_categories(input_category)
    safe_log_info(f"Finding complementary items for {input_category}, looking for: {complementary_categories}")

    for category in complementary_categories:
        items = search_items_by_category(category, input_embedding, limit=30) # é™ä½limit
        if not items:
            safe_log_info(f"No items found for category {category}")
            continue

        safe_log_info(f"Found {len(items)} items for {category}, calculating scores...")

        for item in items:
            score = item['distance']

            # å¤„ç†é¢œè‰²åŒ¹é…
            if input_color != 'unknown' and item['color'] != 'unknown':
                # å°†é€—å·åˆ†éš”çš„é¢œè‰²å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
                input_colors = input_color.split(',')
                item_colors = item['color'].split(',')

                # è®¡ç®—é¢œè‰²åŒ¹é…åº¦
                color_match = False
                for in_color in input_colors:
                    for item_color in item_colors:
                        if in_color == item_color:
                            score += 0.15
                            color_match = True
                            break
                        elif in_color in ['black', 'white', 'gray', 'silver', 'grey'] and item_color in ['black',
                                                                                                         'white',
                                                                                                         'gray',
                                                                                                         'silver',
                                                                                                         'grey']:
                            score += 0.1
                            color_match = True
                            break
                        elif in_color in ['red', 'pink', 'burgundy', 'maroon'] and item_color in ['red', 'pink',
                                                                                                  'burgundy', 'maroon']:
                            score += 0.1
                            color_match = True
                            break
                        elif in_color in ['blue', 'navy', 'indigo', 'teal'] and item_color in ['blue', 'navy', 'indigo',
                                                                                               'teal']:
                            score += 0.1
                            color_match = True
                            break
                        elif in_color in ['green', 'olive', 'lime'] and item_color in ['green', 'olive', 'lime']:
                            score += 0.1
                            color_match = True
                            break
                        elif in_color in ['brown', 'beige', 'tan', 'camel'] and item_color in ['brown', 'beige', 'tan',
                                                                                               'camel']:
                            score += 0.1
                            color_match = True
                            break
                        elif in_color in ['yellow', 'orange', 'coral'] and item_color in ['yellow', 'orange', 'coral']:
                            score += 0.1
                            color_match = True
                            break
                        elif in_color in ['purple', 'violet', 'lavender'] and item_color in ['purple', 'violet',
                                                                                             'lavender']:
                            score += 0.1
                            color_match = True
                            break

                # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ä½†éƒ½æ˜¯ä¸­æ€§è‰²ï¼Œç»™äºˆå°å¥–åŠ±
                if not color_match and any(c in ['black', 'white', 'gray', 'silver', 'grey'] for c in input_colors) and \
                        any(c in ['black', 'white', 'gray', 'silver', 'grey'] for c in item_colors):
                    score += 0.05

            # å¤„ç†æ¬¾å¼åŒ¹é…
            if input_shape != 'unknown' and item['shape'] != 'unknown':
                # å°†é€—å·åˆ†éš”çš„æ¬¾å¼å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
                input_shapes = input_shape.split(',')
                item_shapes = item['shape'].split(',')

                # è®¡ç®—æ¬¾å¼åŒ¹é…åº¦
                for in_shape in input_shapes:
                    for item_shape in item_shapes:
                        if in_shape == item_shape:
                            score += 0.1
                            break
                        elif in_shape in ['skinny', 'slim', 'tight'] and item_shape in ['fitted', 'slim', 'tailored']:
                            score += 0.08
                            break
                        elif in_shape in ['loose', 'oversized', 'relaxed'] and item_shape in ['loose', 'oversized',
                                                                                              'relaxed']:
                            score += 0.08
                            break
                        elif in_shape in ['straight', 'regular'] and item_shape in ['straight', 'regular', 'classic']:
                            score += 0.08
                            break
                        elif in_shape in ['bootcut', 'flare', 'wide'] and item_shape in ['bootcut', 'flare', 'wide']:
                            score += 0.08
                            break

            # å¤„ç†æè´¨åŒ¹é…
            if input_material != 'unknown' and item['material'] != 'unknown':
                # å°†é€—å·åˆ†éš”çš„æè´¨å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
                input_materials = input_material.split(',')
                item_materials = item['material'].split(',')

                # è®¡ç®—æè´¨åŒ¹é…åº¦
                for in_material in input_materials:
                    for item_material in item_materials:
                        if in_material == item_material:
                            score += 0.1
                            break
                        elif in_material in ['cotton', 'linen', 'jersey'] and item_material in ['cotton', 'linen',
                                                                                                'jersey']:
                            score += 0.08
                            break
                        elif in_material in ['leather', 'suede'] and item_material in ['leather', 'suede']:
                            score += 0.08
                            break
                        elif in_material in ['wool', 'cashmere', 'silk'] and item_material in ['wool', 'cashmere',
                                                                                               'silk']:
                            score += 0.08
                            break
                        elif in_material in ['denim'] and item_material in ['cotton', 'jersey']:
                            score += 0.05
                            break
                        elif in_material in ['polyester', 'nylon'] and item_material in ['polyester', 'nylon']:
                            score += 0.05
                            break

            item['match_score'] = score

        # æ‰¾åˆ°æœ€é«˜åˆ†çš„é¡¹ç›®
        best_item = max(items, key=lambda x: x['match_score'])
        recommendations[category] = best_item
        safe_log_info(f"Best item for {category}: {best_item['image_name']} with score {best_item['match_score']}")

    safe_log_info(f"Total recommendations found: {len(recommendations)}")
    return recommendations


def find_most_similar_item_with_attributes(category: str, embedding: np.ndarray) -> Dict:
    if coll is None:
        return {"color": "unknown", "shape": "unknown", "material": "unknown"}
    try:
        search_results = coll.search(
            embedding,
            'embedding',
            param={"metric_type": "IP", "params": {"nprobe": 128}}, # é™ä½nprobe
            limit=30, # é™ä½limit
            expr=f"category == '{category}'",
            output_fields=['color', 'shape', 'material']
        )
        for result in search_results[0]:
            color = getattr(result.entity, 'color', 'unknown')
            shape = getattr(result.entity, 'shape', 'unknown')
            material = getattr(result.entity, 'material', 'unknown')
            if color != 'unknown' or shape != 'unknown' or material != 'unknown':
                return {"color": color, "shape": shape, "material": material}
        if search_results[0]:
            result = search_results[0][0]
            return {
                "color": getattr(result.entity, 'color', 'unknown'),
                "shape": getattr(result.entity, 'shape', 'unknown'),
                "material": getattr(result.entity, 'material', 'unknown')
            }
    except Exception as e:
        safe_log_info(f"Error finding similar item with attributes: {e}")
    return {"color": "unknown", "shape": "unknown", "material": "unknown"}


@app.post("/recommend")
async def recommend_complete_outfit(file: UploadFile = File(...)):
    try:
        img = Image.open(io.BytesIO(await file.read())).convert('RGB')
        safe_log_info(f"Uploaded image size: {img.size}")

        input_category = detect_clothing_category(img)
        safe_log_info(f"Detected category: {input_category}")

        # é¿å…ä½¿ç”¨GPUå¹¶ä½¿ç”¨è¾ƒä½ç²¾åº¦
        inputs = extractor(images=img, return_tensors='pt')['pixel_values']
        with torch.no_grad():
            emb = vit(pixel_values=inputs).last_hidden_state[:, 0, :].cpu().numpy()

        # é‡Šæ”¾è¾“å…¥å˜é‡ä»¥èŠ‚çœå†…å­˜
        del inputs
        import gc
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶

        input_attributes = find_most_similar_item_with_attributes(input_category, emb)
        input_color = input_attributes["color"]
        input_shape = input_attributes["shape"]
        input_material = input_attributes["material"]

        # è®°å½•è¾“å…¥å±æ€§
        safe_log_info(f"Input attributes - Color: {input_color}, Shape: {input_shape}, Material: {input_material}")

        recommendations = get_complementary_items(
            input_category, emb, input_color, input_shape, input_material)

        safe_log_info(f"Recommendations received: {recommendations}")

        final_outfit = {}
        selected_categories = []
        if input_category != 'unknown':
            selected_categories.append(input_category)

        # æ”¹è¿›é€‰æ‹©é€»è¾‘
        if input_category in ['top', 'outer', 'dress']:
            if 'shoes' in recommendations:  # ä¼˜å…ˆé€‰æ‹©é‹å­
                selected_categories.append('shoes')
            if 'bag' in recommendations:  # ç„¶åé€‰æ‹©åŒ…
                selected_categories.append('bag')
            if 'belt' in recommendations and len(selected_categories) < 3:  # ç„¶åé€‰æ‹©è…°å¸¦
                selected_categories.append('belt')
            if 'outer' in recommendations and len(selected_categories) < 3:  # å¤–å¥—
                selected_categories.append('outer')
        elif input_category in ['pants', 'skirt', 'bottom']:
            if 'top' in recommendations:  # ä¸Šè¡£
                selected_categories.append('top')
            if 'shoes' in recommendations:  # é‹å­
                selected_categories.append('shoes')
            if 'bag' in recommendations and len(selected_categories) < 3:  # åŒ…
                selected_categories.append('bag')
        elif input_category == 'shoes':
            if 'pants' in recommendations:  # è£¤å­
                selected_categories.append('pants')
            elif 'skirt' in recommendations:  # è£™å­
                selected_categories.append('skirt')
            if 'top' in recommendations and len(selected_categories) < 3:  # ä¸Šè¡£
                selected_categories.append('top')
            if 'bag' in recommendations and len(selected_categories) < 3:  # åŒ…
                selected_categories.append('bag')
        else:
            # é€šç”¨é€‰æ‹©é€»è¾‘
            priority_categories = ['shoes', 'bag', 'belt', 'outer', 'top', 'pants', 'skirt']
            for cat in priority_categories:
                if cat in recommendations and len(selected_categories) < 3 and cat != input_category:
                    selected_categories.append(cat)

        safe_log_info(f"Selected categories: {selected_categories}")

        # æ„å»ºæœ€ç»ˆæ­é…
        for category in selected_categories:
            if category in recommendations:
                final_outfit[category] = recommendations[category]

        safe_log_info(f"Final outfit: {final_outfit}")

        # ä½¿ç”¨0.6Bæ¨¡å‹ç”Ÿæˆè¦ç‚¹
        # æ„é€ ä¸è®­ç»ƒæ•°æ®æ ¼å¼ç›¸ä¼¼çš„è¾“å…¥
        category_names = {
            'top': 'ä¸Šè¡£',
            'bottom': 'ä¸‹è£…',
            'pants': 'è£¤å­',
            'skirt': 'è£™å­',
            'dress': 'è¿è¡£è£™',
            'outer': 'å¤–å¥—',
            'shoes': 'é‹å­',
            'bag': 'åŒ…è¢‹',
            'belt': 'è…°å¸¦',
            'hat': 'å¸½å­',
            'scarf': 'å›´å·¾',
            'accessories': 'é…é¥°'
        }

        chinese_category = category_names.get(input_category, input_category)

        # æ„å»ºè¾“å‡ºæ ¼å¼
        if final_outfit:
            # å¦‚æœæœ‰æ¨èæ­é…ï¼Œç›´æ¥å°†Milvusæ£€ç´¢ç»“æœè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            outline_points = []
            for i, (category, item) in enumerate(final_outfit.items(), 1):
                color = item.get('color', 'unknown')
                shape = item.get('shape', 'unknown')
                material = item.get('material', 'unknown')
                chinese_cat = category_names.get(category, category)
                outline_points.append(f"{i}. æ­é…{chinese_cat}(é¢œè‰²:{color},æ¬¾å¼:{shape},æè´¨:{material})")

            # å°†åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œæ¯è¡Œä¸€ä¸ªè¦ç‚¹
            outline_text = "\n".join(outline_points)
        else:
            # å¦‚æœæ²¡æœ‰æ¨èæ­é…ï¼Œè®©æœ¬åœ°æ¨¡å‹ç”Ÿæˆæ­é…å»ºè®®
            outline_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ—¶å°šæ­é…å¸ˆï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„å•å“æä¾›3-5æ¡æ ¸å¿ƒæ­é…å»ºè®®ã€‚

            ç”¨æˆ·å•å“ï¼š{input_color}{chinese_category}

            è¦æ±‚ï¼š
            1. æ­é…å»ºè®®åº”è‡ªç„¶æµç•…ï¼Œçªå‡ºæ•´ä½“é€ å‹æ•ˆæœ
            2. ç»“åˆé¢œè‰²ã€æ¬¾å¼ã€æè´¨ç­‰è¦ç´ ï¼Œä½“ç°é£æ ¼ç‰¹ç‚¹
            3. å»ºè®®å¯æ¶‰åŠä¸Šè¡£ã€ä¸‹è£…ã€å¤–å¥—ã€é‹åŒ…ã€é…é¥°ç­‰ä¸åŒå“ç±»
            4. æ¯æ¡å»ºè®®ä¹‹é—´ä¿æŒå¤šæ ·åŒ–
            5. ä¸è¦è¾“å‡ºé¢å¤–è§£é‡Šæˆ–å…è´£å£°æ˜

            è¯·ç›´æ¥ç»™å‡ºæ­é…å»ºè®®ï¼š
            """

            outline_text = generate_outline_local(outline_prompt, max_tokens=500)
        safe_log_info(f"Generated outline text: {outline_text}")

        # ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡æ–‡æ¡ˆ
        if LLM_API_KEY:
            # æ„é€ ç»™å¤§æ¨¡å‹çš„æç¤ºè¯ï¼Œè®©æ¨¡å‹è¾“å‡ºåŒ…å«ç”¨æˆ·å•å“ä¿¡æ¯å’Œç©¿æ­å»ºè®®
            final_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¶å°šæ­é…å¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆè¯¦ç»†çš„ç©¿æ­å»ºè®®ï¼š

            ç”¨æˆ·ä¸Šä¼ çš„å•å“ä¿¡æ¯ï¼š
            - å“ç±»ï¼š{input_category}
            - é¢œè‰²ï¼š{input_color}
            - æ¬¾å¼ï¼š{input_shape if input_shape != 'unknown' else 'æœªè¯†åˆ«'}
            - æè´¨ï¼š{input_material if input_material != 'unknown' else 'æœªè¯†åˆ«'}

            æ£€ç´¢åˆ°çš„æ¨èæ­é…è¡£å“æˆ–ä¸Šæ¸¸æœ¬åœ°å¤§æ¨¡å‹ç”Ÿæˆçš„æ¨èæ­é…è¦ç‚¹ï¼š
            {outline_text}

            æ³¨æ„ä¸Šæ¸¸æ¨¡å‹ç”Ÿäº§å†…å®¹ä¼šæœ‰ä¸€äº›æ— ç”¨ä¿¡æ¯æˆ–é”™è¯¯ä¿¡æ¯ï¼Œè¯·æ­£ç¡®è¯†åˆ«ä¿ç•™æœ‰æ•ˆçš„ä¿¡æ¯ï¼Œä½œä¸ºç©¿æ­è¦ç‚¹ï¼š

            è¯·ç”¨ä¸­æ–‡æä¾›è¯¦ç»†ä¸”å®ç”¨çš„ç©¿æ­å»ºè®®ï¼Œè¦æ±‚ï¼š
            1. é¦–å…ˆæè¿°ç”¨æˆ·å•å“çš„ç‰¹ç‚¹å’Œæ­é…ä¼˜åŠ¿
            2. è¯¦ç»†è¯´æ˜æ¯ä¸ªæ¨èå•å“çš„æ­é…ç†ç”±
            3. ç»™å‡ºæ•´ä½“æ­é…çš„é£æ ¼æè¿°
            4. æä¾›é€‚åˆçš„ç©¿ç€åœºæ™¯
            5. ç»™å‡ºä¸ªæ€§åŒ–è°ƒæ•´å»ºè®®
            6. æä¾›è´­ä¹°å…³é”®è¯ä»¥ä¾¿ç”¨æˆ·æœç´¢ç±»ä¼¼å•å“

            è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
            ğŸ“Œ å•å“åˆ†æ
            [ç”¨æˆ·å•å“çš„ç‰¹ç‚¹å’Œæ­é…ä¼˜åŠ¿]

            ğŸ‘— æ­é…å»ºè®®
            [è¯¦ç»†è¯´æ˜æ¯ä¸ªæ¨èå•å“çš„æ­é…ç†ç”±]

            ğŸ’„ é£æ ¼å®šä½
            [æ•´ä½“æ­é…çš„é£æ ¼æè¿°]

            ğŸ¯ é€‚ç”¨åœºæ™¯
            [é€‚åˆçš„ç©¿ç€åœºæ™¯]

            ğŸ¨ ä¸ªæ€§è°ƒæ•´
            [ä¸ªæ€§åŒ–è°ƒæ•´å»ºè®®]

            ğŸ›ï¸ è´­ä¹°æŒ‡å—
            [è´­ä¹°å…³é”®è¯ï¼Œå¸®åŠ©ç”¨æˆ·æœç´¢ç±»ä¼¼å•å“]"""

            outfit_text = call_qwen_api(final_prompt)
        else:
            # å¦‚æœæ²¡æœ‰APIå¯†é’¥ï¼Œç›´æ¥ä½¿ç”¨è¦ç‚¹ä½œä¸ºè¾“å‡º
            outfit_text = f"æ ¸å¿ƒæ­é…è¦ç‚¹ï¼š\n{outline_text}\n\næ³¨æ„ï¼šå¦‚éœ€ç”Ÿæˆè¯¦ç»†æ–‡æ¡ˆï¼Œè¯·é…ç½®å¤§æ¨¡å‹APIå¯†é’¥ã€‚"

        safe_log_info(f"Generated outfit text length: {len(outfit_text)}")
        try:
            safe_log_info(f"Generated outfit text preview: {outfit_text[:500]}...")
        except:
            safe_log_info("Generated outfit text preview: [Contains special characters]")

        # ç®€åŒ–è¿”å›ç»“æ„ï¼Œåªè¿”å›ä¸€ä¸ªæ¨¡å‹è¾“å‡º
        return {
            "outfit_description": outfit_text
        }

    except Exception as e:
        safe_log_info(f"Error in recommend_complete_outfit: {e}")
        import traceback
        safe_log_info(traceback.format_exc())
        return {
            "outfit_description": f"å¤„ç†å‡ºé”™: {str(e)}"
        }


@app.get("/health")
async def health_check():
    return {"status": "healthy"}


def main():
    import uvicorn
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        workers=1,
        log_level="info",
        timeout_keep_alive=30  # å‡å°‘keep-aliveè¶…æ—¶
    )


if __name__ == "__main__":
    main()
