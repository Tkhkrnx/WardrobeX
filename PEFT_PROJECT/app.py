# app.py
from contextlib import asynccontextmanager
from fastapi import FastAPI, File, UploadFile
from PIL import Image
import torch
from transformers import (
    ViTImageProcessor,
    ViTModel,
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig
)
from pymilvus import connections, Collection
import numpy as np
import io
import re
import cv2
import os
from ultralytics import YOLO
from typing import List, Dict
from peft import PeftModel
from langchain_openai import ChatOpenAI
import logging
from dotenv import load_dotenv
import gc
import traceback
import asyncio
import time

load_dotenv(override=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("app.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# åˆ›å»ºå®‰å…¨çš„æ—¥å¿—è®°å½•å‡½æ•°
def safe_log_info(message, *args, **kwargs):
    try:
        logger.info(message, *args, **kwargs)
    except UnicodeEncodeError:
        # å¤„ç†å¯èƒ½åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ¶ˆæ¯
        if isinstance(message, str):
            safe_message = message.encode('utf-8', errors='replace').decode('utf-8')
            logger.info(safe_message, *args, **kwargs)
        else:
            logger.info(message, *args, **kwargs)


app = FastAPI()

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨æ¨¡å‹
extractor = None
vit = None
coll = None
yolo_model = None
# æ–‡æ¡ˆç”Ÿæˆæ¨¡å‹ç›¸å…³
text_tokenizer = None
text_model = None
# å¼ºæ¨¡å‹APIé…ç½®
LLM_API_KEY = os.getenv("LLM_API_KEY")
LLM_BASE_URL = "https://www.chataiapi.com/v1"
LLM_MODEL_NAME = os.getenv("LLM_MODEL_NAME", "claude-3-5-sonnet-20241022")

# é‡åŒ–æ§åˆ¶ï¼šç¯å¢ƒå˜é‡ QUANT_BITS = "4" æˆ– "8"
QUANT_BITS = os.getenv("QUANT_BITS", "4").strip()

class_names = {}


@asynccontextmanager
async def lifespan(app: FastAPI):
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    load_models()
    yield
    # å…³é—­æ—¶æ‰§è¡Œï¼ˆå¦‚æœéœ€è¦ï¼‰
    # åœ¨åº”ç”¨é€€å‡ºæ—¶æ¸…ç†ï¼ˆå¦‚æœæœ‰å¿…è¦ï¼‰
    try:
        safe_log_info("Shutting down - clearing models from memory.")
        global vit, text_model
        del vit
        del text_model
        gc.collect()
        try:
            torch.cuda.empty_cache()
        except Exception:
            pass
    except Exception as e:
        safe_log_info(f"Error during shutdown cleanup: {e}")


app = FastAPI(lifespan=lifespan)


def _get_quant_kwargs():
    quant_kwargs = {}
    if QUANT_BITS == "4":
        try:
            bnb_config = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_use_double_quant=True,
                bnb_4bit_quant_type="nf4",
                bnb_4bit_compute_dtype=torch.bfloat16 if hasattr(torch, "bfloat16") else torch.float16
            )
            quant_kwargs.update({
                "quantization_config": bnb_config,
                "device_map": "auto",
                "low_cpu_mem_usage": True
            })
            safe_log_info("Configured 4-bit (NF4) quantization parameters.")
            return quant_kwargs
        except Exception as e:
            safe_log_info(f"Failed to create 4-bit BitsAndBytesConfig: {e}")
            safe_log_info("Falling back to 8-bit configuration.")
    try:
        quant_kwargs.update({
            "load_in_8bit": True,
            "device_map": "auto",
            "low_cpu_mem_usage": True
        })
        safe_log_info("Configured 8-bit quantization parameters.")
    except Exception as e:
        safe_log_info(f"Failed to configure 8-bit params: {e}")
    return quant_kwargs


def load_models():
    """
    åŠ è½½æ‰€æœ‰æ¨¡å‹ï¼ˆå°½é‡ä½¿ç”¨é‡åŒ–åŠ è½½ä»¥å‡å°å†…å­˜ï¼‰
    """
    global extractor, vit, coll, yolo_model, text_tokenizer, text_model

    safe_log_info("Loading models...")

    # åŠ è½½ ViT ç‰¹å¾æå–å™¨
    try:
        extractor = ViTImageProcessor.from_pretrained('/data/google/vit-base-patch16-224')
        safe_log_info("ViTImageProcessor loaded.")
    except Exception as e:
        safe_log_info(f"Failed to load ViTImageProcessor: {e}")
        safe_log_info(traceback.format_exc())

    # åŠ è½½åŸºç¡€ ViT æ¨¡å‹ï¼Œä¼˜å…ˆ float16 ä»¥èŠ‚çœæ˜¾å­˜ï¼Œfallback åˆ° float32
    try:
        safe_log_info("Loading ViT model with float16 precision...")
        vit = ViTModel.from_pretrained('/data/google/vit-base-patch16-224',
                                       torch_dtype=torch.float16,
                                       low_cpu_mem_usage=True)
        safe_log_info("ViT model loaded with float16 precision.")
    except Exception as e:
        safe_log_info(f"Failed to load ViT model with float16: {e}")
        safe_log_info("Trying fallback to float32 load...")
        try:
            vit = ViTModel.from_pretrained('/data/google/vit-base-patch16-224',
                                           torch_dtype=torch.float32,
                                           low_cpu_mem_usage=True)
            safe_log_info("ViT model loaded with float32 precision.")
        except Exception as e2:
            safe_log_info(f"Failed to load ViT model entirely: {e2}")
            safe_log_info(traceback.format_exc())
            vit = None

    # åŠ è½½ä½¿ç”¨ LoRA å¾®è°ƒçš„æœ€ä½³æ¨¡å‹æƒé‡ï¼ˆå¦‚å­˜åœ¨ï¼‰
    try:
        if vit is not None and os.path.exists('outputs/vit_lora_best_peft') and os.path.isdir('outputs/vit_lora_best_peft'):
            config_file = os.path.join('outputs/vit_lora_best_peft', 'adapter_config.json')
            if os.path.exists(config_file):
                try:
                    vit = PeftModel.from_pretrained(vit, 'outputs/vit_lora_best_peft')
                    try:
                        vit = vit.merge_and_unload()
                        safe_log_info("LoRA model merged and loaded into ViT.")
                    except Exception:
                        safe_log_info("LoRA loaded but merge_and_unload not supported/failed; using PeftModel wrapper.")
                except Exception as e:
                    safe_log_info(f"Failed to apply LoRA to ViT: {e}")
            else:
                safe_log_info("LoRA config file not found, using base ViT model")
        else:
            safe_log_info("LoRA model directory not found, using base ViT model")
    except Exception as e:
        safe_log_info(f"Failed to load LoRA model: {e}")

    try:
        if vit is not None:
            vit.eval()
    except Exception as e:
        safe_log_info(f"Failed to set ViT eval: {e}")

    # åŠ è½½æœ¬åœ°å¾®è°ƒçš„æ–‡æ¡ˆç”Ÿæˆæ¨¡å‹ (Prompt Tuning) ä½¿ç”¨é‡åŒ–é…ç½®
    try:
        safe_log_info("Loading fine-tuned text generation model (tokenizer first)...")
        base_model_name = '/data/Qwen3-0.6B'
        text_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)
        if text_tokenizer.pad_token is None:
            text_tokenizer.pad_token = text_tokenizer.eos_token

        safe_log_info("Preparing to load base text model with quantization (if available)...")

        # ** è¿™é‡Œæ”¹ä¸ºè°ƒç”¨ _get_quant_kwargs() å‡½æ•°ï¼Œç¡®ä¿é‡åŒ–å‚æ•°è·å–ç»Ÿä¸€ **
        quant_kwargs = _get_quant_kwargs()

        text_model = None
        load_success = False

        # å°è¯•ä½¿ç”¨é‡åŒ–åŠ è½½ï¼ˆ4-bit æˆ– 8-bitï¼‰
        try:
            text_model = AutoModelForCausalLM.from_pretrained(
                base_model_name,
                trust_remote_code=True,
                **quant_kwargs
            )
            load_success = True
            safe_log_info("Base text model loaded with quantization parameters.")
        except Exception as e:
            safe_log_info(f"Quantized load failed for text model: {e}")
            safe_log_info("Trying fallback to float16 low_cpu_mem_usage load...")
            try:
                text_model = AutoModelForCausalLM.from_pretrained(
                    base_model_name,
                    trust_remote_code=True,
                    torch_dtype=torch.float16,
                    low_cpu_mem_usage=True
                )
                load_success = True
                safe_log_info("Base text model loaded with float16 fallback.")
            except Exception as e2:
                safe_log_info(f"Fallback load failed for text model: {e2}")
                safe_log_info(traceback.format_exc())

        if not load_success:
            safe_log_info("Text model could not be loaded in any optimized mode. Setting text_model to None.")
            text_model = None
        else:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è®­ç»ƒåæœ€å¥½çš„ PEFT æƒé‡
            best_model_path = 'outputs/qwen3_0.6b_prompt_best'
            final_model_path = 'outputs/qwen3_0.6b_prompt_final'

            if os.path.exists(best_model_path) and os.path.isdir(best_model_path):
                config_file = os.path.join(best_model_path, 'adapter_config.json')
                if os.path.exists(config_file):
                    try:
                        text_model = PeftModel.from_pretrained(text_model, best_model_path)
                        text_model.eval()
                        safe_log_info("Best Prompt Tuning model loaded successfully from qwen3_0.6b_prompt_best!")
                    except Exception as e:
                        safe_log_info(f"Failed to load PEFT best model: {e}")
                        safe_log_info(traceback.format_exc())
                else:
                    safe_log_info("Best Prompt Tuning config file not found, checking final model...")
                    if os.path.exists(final_model_path) and os.path.isdir(final_model_path):
                        config_file2 = os.path.join(final_model_path, 'adapter_config.json')
                        if os.path.exists(config_file2):
                            try:
                                text_model = PeftModel.from_pretrained(text_model, final_model_path)
                                text_model.eval()
                                safe_log_info("Final Prompt Tuning model loaded successfully from qwen3_0.6b_prompt_final!")
                            except Exception as e:
                                safe_log_info(f"Failed to load PEFT final model: {e}")
                                safe_log_info(traceback.format_exc())
                        else:
                            safe_log_info("Final Prompt Tuning config file not found, using base model")
                    else:
                        safe_log_info("Prompt Tuning model directory not found, using base model")
            else:
                safe_log_info("Best Prompt Tuning model directory not found, checking final model...")
                if os.path.exists(final_model_path) and os.path.isdir(final_model_path):
                    config_file2 = os.path.join(final_model_path, 'adapter_config.json')
                    if os.path.exists(config_file2):
                        try:
                            text_model = PeftModel.from_pretrained(text_model, final_model_path)
                            text_model.eval()
                            safe_log_info("Final Prompt Tuning model loaded successfully from qwen3_0.6b_prompt_final!")
                        except Exception as e:
                            safe_log_info(f"Failed to load PEFT final model: {e}")
                            safe_log_info(traceback.format_exc())
                    else:
                        safe_log_info("Final Prompt Tuning config file not found, using base model")
                else:
                    safe_log_info("Prompt Tuning model directory not found, using base model")

            try:
                if text_model is not None:
                    text_model.eval()
            except Exception as e:
                safe_log_info(f"Failed to set text_model eval: {e}")

        safe_log_info("Fine-tuned text generation model loading finished.")
    except Exception as e:
        safe_log_info(f"Failed to load fine-tuned text model: {e}")
        safe_log_info(traceback.format_exc())
        text_tokenizer = None
        text_model = None


    # è¿æ¥ Milvus
    try:
        connections.connect(host='150.158.55.76', port='19530')
        coll = Collection('fashion_features')
        coll.load()
        safe_log_info("Milvus connected successfully!")
    except Exception as e:
        safe_log_info(f"Failed to connect to Milvus: {e}")
        coll = None

    # åŠ è½½ YOLO æ¨¡å‹ç”¨äºæ£€æµ‹è¡£ç‰©ç±»å‹ï¼ˆå‡å°‘æ—¥å¿—è¾“å‡ºï¼‰
    try:
        yolo_model = YOLO('modanet_clothing_model.pt')
        # å‡å°‘YOLOæ¨¡å‹çš„æ—¥å¿—è¾“å‡º
        if hasattr(yolo_model, 'names') and yolo_model.names:
            class_names.update(yolo_model.names)
        else:
            class_names.update({
                0: 'top', 1: 'bottom', 2: 'dress', 3: 'outer', 4: 'pants',
                5: 'skirt', 6: 'headwear', 7: 'eyewear', 8: 'bag', 9: 'shoes',
                10: 'belt', 11: 'socks', 12: 'tights', 13: 'gloves', 14: 'scarf'
            })
        safe_log_info("YOLO model loaded successfully!")
    except Exception as e:
        safe_log_info(f"Failed to load YOLO model: {e}")
        yolo_model = None
        class_names.update({
            0: 'top', 1: 'bottom', 2: 'dress', 3: 'outer', 4: 'pants',
            5: 'skirt', 6: 'headwear', 7: 'eyewear', 8: 'bag', 9: 'shoes',
            10: 'belt', 11: 'socks', 12: 'tights', 13: 'gloves', 14: 'scarf'
        })

    safe_log_info("All models loaded (or attempted). Current memory state:")
    try:
        safe_log_info(f" - ViT loaded: {vit is not None}")
        safe_log_info(f" - Text model loaded: {text_model is not None}")
        safe_log_info(f" - Tokenizer loaded: {text_tokenizer is not None}")
        safe_log_info(f" - Milvus collection: {coll is not None}")
        safe_log_info(f" - YOLO loaded: {yolo_model is not None}")
    except Exception:
        pass


def generate_outline_local(prompt: str, max_tokens: int = 100) -> str:
    """
    ä½¿ç”¨æœ¬åœ°å¾®è°ƒæ¨¡å‹ç”Ÿæˆæ­é…è¦ç‚¹
    """
    global text_tokenizer, text_model
    if text_tokenizer is None or text_model is None:
        return "æ–‡æ¡ˆç”Ÿæˆæ¨¡å‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„ã€‚"

    try:
        # å¯¹æç¤ºè¿›è¡Œé¢„å¤„ç†ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
        if not prompt.strip():
            return "è¾“å…¥æç¤ºä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆæ–‡æ¡ˆã€‚"

        # æ¸…ç†æç¤ºè¯ï¼Œç¡®ä¿æ²¡æœ‰å¤šä½™çš„ç©ºç™½å­—ç¬¦
        prompt = prompt.strip()

        # ä½¿ç”¨float16ç²¾åº¦å¹¶é¿å…ä½¿ç”¨GPU
        inputs = text_tokenizer(prompt, return_tensors='pt', padding=True, truncation=True, max_length=512)

        with torch.no_grad():
            outputs = text_model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                pad_token_id=text_tokenizer.pad_token_id,
                eos_token_id=text_tokenizer.eos_token_id,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1,
                length_penalty=1.0,
                no_repeat_ngram_size=3
                # ç§»é™¤äº† early_stopping å‚æ•°ï¼Œå› ä¸ºå®ƒä¸è¢«å½“å‰ç‰ˆæœ¬æ”¯æŒ
            )
            text = text_tokenizer.decode(outputs[0], skip_special_tokens=True)
            # ç§»é™¤è¾“å…¥éƒ¨åˆ†ï¼Œåªè¿”å›ç”Ÿæˆçš„éƒ¨åˆ†
            generated_text = text[len(prompt):].strip()

        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦æœ‰æ•ˆ
        if not generated_text or len(generated_text) < 5:
            return "æ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„æ­é…è¦ç‚¹ï¼Œè¯·ç¨åé‡è¯•ã€‚"

        return generated_text
    except Exception as e:
        safe_log_info(f"Error generating outline with local model: {e}")
        safe_log_info(traceback.format_exc())
        # è¿”å›ä¸€ä¸ªé»˜è®¤çš„æ­é…å»ºè®®
        return "å»ºè®®é€‰æ‹©ç®€çº¦é£æ ¼çš„é‹å­æ¥å¹³è¡¡æ•´ä½“é€ å‹ï¼Œæ­é…ä¸€æ¬¾æ—¶å°šçš„åŒ…è¢‹å¢åŠ äº®ç‚¹ï¼Œæ ¹æ®å­£èŠ‚é€‰æ‹©åˆé€‚çš„å¤–å¥—è¿›è¡Œå ç©¿ã€‚"


def call_qwen_api(prompt: str) -> str:
    """
    è°ƒç”¨APIç”Ÿæˆé«˜è´¨é‡æ–‡æ¡ˆ
    """
    if not LLM_API_KEY:
        return "APIå¯†é’¥æœªé…ç½®ï¼Œæ— æ³•è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ–‡æ¡ˆã€‚"

    try:
        llm = ChatOpenAI(
            temperature=0.7,
            model=LLM_MODEL_NAME,
            api_key=LLM_API_KEY,
            base_url=LLM_BASE_URL,
            request_timeout=30  # æ·»åŠ 30ç§’è¶…æ—¶
        )

        response = llm.invoke(prompt)
        return response.content
    except Exception as e:
        safe_log_info(f"Error calling Qwen API: {e}")
        safe_log_info(traceback.format_exc())
        return "è°ƒç”¨å¤§æ¨¡å‹APIæ—¶å‡ºé”™ï¼Œè¯·ç¨åé‡è¯•ã€‚"


def detect_clothing_category(image: Image.Image) -> str:
    """
    ä½¿ç”¨YOLOæ¨¡å‹æ£€æµ‹è¡£ç‰©ç±»åˆ«
    """
    global class_names, yolo_model

    # å¦‚æœYOLOæ¨¡å‹æœªåŠ è½½ï¼Œç›´æ¥è¿”å›unknown
    if yolo_model is None:
        safe_log_info("YOLO model not loaded")
        return 'unknown'

    try:
        # å°†PILå›¾åƒè½¬æ¢ä¸ºOpenCVæ ¼å¼ï¼ˆåœ¨å†…å­˜ä¸­ï¼‰
        # å…ˆè½¬æ¢ä¸ºnumpyæ•°ç»„
        img_array = np.array(image)
        # RGBè½¬BGRï¼ˆPILä½¿ç”¨RGBï¼ŒOpenCVä½¿ç”¨BGRï¼‰
        cv_image = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

        safe_log_info(f"Input image size: {img_array.shape}")

        # ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œæ£€æµ‹ï¼Œå°è¯•ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼
        results = yolo_model.predict(source=cv_image, conf=0.1)  # è¿›ä¸€æ­¥é™ä½ç½®ä¿¡åº¦é˜ˆå€¼

        safe_log_info(f"Detection results: {results}")

        # è·å–æ£€æµ‹åˆ°çš„ç±»åˆ«
        for r in results:
            if hasattr(r, 'boxes') and r.boxes is not None and len(r.boxes) > 0:
                # æ‰“å°æ£€æµ‹åˆ°çš„æ‰€æœ‰æ¡†çš„ä¿¡æ¯
                confs = r.boxes.conf.cpu().numpy()
                classes = r.boxes.cls.cpu().numpy()

                safe_log_info(f"Detected boxes - confidences: {confs}, classes: {classes}")

                if len(confs) > 0:
                    # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œå–æœ€é«˜çš„
                    sorted_indices = np.argsort(confs)[::-1]  # é™åºæ’åˆ—
                    for idx in sorted_indices:
                        conf = confs[idx]
                        class_id = int(classes[idx])

                        safe_log_info(f"Checking detection - confidence: {conf}, class_id: {class_id}")

                        # ä½¿ç”¨å…¨å±€class_namesæ˜ å°„è·å–ç±»åˆ«åç§°
                        detected_class_name = class_names.get(class_id, 'unknown')
                        safe_log_info(f"Detected class name: {detected_class_name}")

                        # åªè¦ç½®ä¿¡åº¦å¤§äºä¸€å®šé˜ˆå€¼å°±è¿”å›
                        if conf > 0.05:  # éå¸¸ä½çš„é˜ˆå€¼
                            return detected_class_name

    except Exception as e:
        safe_log_info(f"Error in detect_clothing_category: {e}")
        safe_log_info(traceback.format_exc())

    safe_log_info("No valid detection found, returning 'unknown'")
    return 'unknown'

def get_complementary_categories(input_category: str) -> List[str]:
    complementary_map = {
        'top': ['bottom', 'pants', 'skirt', 'shoes', 'bag'],
        'bottom': ['top', 'shoes', 'bag'],
        'pants': ['top', 'shoes', 'bag'],
        'skirt': ['top', 'shoes', 'bag'],
        'dress': ['shoes', 'bag', 'belt', 'outer'],  # ä¸ºdresså¢åŠ æ›´å¤šæ­é…é€‰é¡¹
        'outer': ['top', 'bottom', 'pants', 'skirt', 'shoes', 'bag'],
        'shoes': ['top', 'bottom', 'pants', 'skirt', 'dress'],
        'bag': ['top', 'bottom', 'pants', 'skirt', 'dress', 'shoes'],
        'headwear': ['top', 'dress'],
        'belt': ['pants', 'skirt', 'dress'],
        'unknown': ['top', 'bottom', 'pants', 'skirt', 'dress', 'shoes', 'bag', 'outer']
    }
    return complementary_map.get(input_category, ['top', 'bottom', 'shoes', 'bag'])


def search_items_by_category(category: str, input_embedding: np.ndarray, limit: int = 20) -> List[Dict]:
    if coll is None:
        return []
    try:
        # ç¡®ä¿å‘é‡ç±»å‹ä¸ºfloat32ä»¥åŒ¹é…Milvusä¸­çš„VECTOR_FLOATç±»å‹
        if input_embedding.dtype != np.float32:
            input_embedding = input_embedding.astype(np.float32)

        # æ·»åŠ è¶…æ—¶å’Œé”™è¯¯å¤„ç†
        search_results = coll.search(
            input_embedding,
            'embedding',
            param={"metric_type": "IP", "params": {"nprobe": 128}},  # è¿›ä¸€æ­¥é™ä½nprobe
            limit=limit,
            expr=f"category == '{category}'",
            output_fields=['image_name', 'color', 'shape', 'material'],
            timeout=10.0  # æ·»åŠ 10ç§’è¶…æ—¶
        )
        items = []
        for result in search_results[0]:
            try:
                items.append({
                    "id": result.id,
                    "image_name": result.entity.image_name,
                    "category": category,
                    "color": getattr(result.entity, 'color', 'unknown'),
                    "shape": getattr(result.entity, 'shape', 'unknown'),
                    "material": getattr(result.entity, 'material', 'unknown'),
                    "distance": result.distance
                })
            except Exception as e:
                safe_log_info(f"Error processing search result: {e}")
                continue
        safe_log_info(f"Found {len(items)} items for category {category}")
        return items
    except Exception as e:
        safe_log_info(f"Error searching items by category {category}: {e}")
        safe_log_info(traceback.format_exc())
        return []


def get_complementary_items(input_category: str, input_embedding: np.ndarray,
                            input_color: str = 'unknown', input_shape: str = 'unknown',
                            input_material: str = 'unknown') -> Dict[str, Dict]:
    recommendations = {}
    complementary_categories = get_complementary_categories(input_category)
    safe_log_info(f"Finding complementary items for {input_category}, looking for: {complementary_categories}")

    for category in complementary_categories:
        # æ·»åŠ è¶…æ—¶ä¿æŠ¤å’Œé”™è¯¯å¤„ç†
        try:
            items = search_items_by_category(category, input_embedding, limit=30)  # é™ä½limit
            if not items:
                safe_log_info(f"No items found for category {category}")
                continue

            safe_log_info(f"Found {len(items)} items for {category}, calculating scores...")

            for item in items:
                score = item['distance']

                # å¤„ç†é¢œè‰²åŒ¹é…
                if input_color != 'unknown' and item['color'] != 'unknown':
                    # å°†é€—å·åˆ†éš”çš„é¢œè‰²å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
                    input_colors = input_color.split(',')
                    item_colors = item['color'].split(',')

                    # è®¡ç®—é¢œè‰²åŒ¹é…åº¦
                    color_match = False
                    for in_color in input_colors:
                        for item_color in item_colors:
                            if in_color == item_color:
                                score += 0.15
                                color_match = True
                                break
                            elif in_color in ['black', 'white', 'gray', 'silver', 'grey'] and item_color in ['black',
                                                                                                             'white',
                                                                                                             'gray',
                                                                                                             'silver',
                                                                                                             'grey']:
                                score += 0.1
                                color_match = True
                                break
                            elif in_color in ['red', 'pink', 'burgundy', 'maroon'] and item_color in ['red', 'pink',
                                                                                                      'burgundy',
                                                                                                      'maroon']:
                                score += 0.1
                                color_match = True
                                break
                            elif in_color in ['blue', 'navy', 'indigo', 'teal'] and item_color in ['blue', 'navy',
                                                                                                   'indigo',
                                                                                                   'teal']:
                                score += 0.1
                                color_match = True
                                break
                            elif in_color in ['green', 'olive', 'lime'] and item_color in ['green', 'olive', 'lime']:
                                score += 0.1
                                color_match = True
                                break
                            elif in_color in ['brown', 'beige', 'tan', 'camel'] and item_color in ['brown', 'beige',
                                                                                                   'tan',
                                                                                                   'camel']:
                                score += 0.1
                                color_match = True
                                break
                            elif in_color in ['yellow', 'orange', 'coral'] and item_color in ['yellow', 'orange',
                                                                                              'coral']:
                                score += 0.1
                                color_match = True
                                break
                            elif in_color in ['purple', 'violet', 'lavender'] and item_color in ['purple', 'violet',
                                                                                                 'lavender']:
                                score += 0.1
                                color_match = True
                                break

                    # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ä½†éƒ½æ˜¯ä¸­æ€§è‰²ï¼Œç»™äºˆå°å¥–åŠ±
                    if not color_match and any(
                            c in ['black', 'white', 'gray', 'silver', 'grey'] for c in input_colors) and \
                            any(c in ['black', 'white', 'gray', 'silver', 'grey'] for c in item_colors):
                        score += 0.05

                # å¤„ç†æ¬¾å¼åŒ¹é…
                if input_shape != 'unknown' and item['shape'] != 'unknown':
                    # å°†é€—å·åˆ†éš”çš„æ¬¾å¼å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
                    input_shapes = input_shape.split(',')
                    item_shapes = item['shape'].split(',')

                    # è®¡ç®—æ¬¾å¼åŒ¹é…åº¦
                    for in_shape in input_shapes:
                        for item_shape in item_shapes:
                            if in_shape == item_shape:
                                score += 0.1
                                break
                            elif in_shape in ['skinny', 'slim', 'tight'] and item_shape in ['fitted', 'slim',
                                                                                            'tailored']:
                                score += 0.08
                                break
                            elif in_shape in ['loose', 'oversized', 'relaxed'] and item_shape in ['loose', 'oversized',
                                                                                                  'relaxed']:
                                score += 0.08
                                break
                            elif in_shape in ['straight', 'regular'] and item_shape in ['straight', 'regular',
                                                                                        'classic']:
                                score += 0.08
                                break
                            elif in_shape in ['bootcut', 'flare', 'wide'] and item_shape in ['bootcut', 'flare',
                                                                                             'wide']:
                                score += 0.08
                                break

                # å¤„ç†æè´¨åŒ¹é…
                if input_material != 'unknown' and item['material'] != 'unknown':
                    # å°†é€—å·åˆ†éš”çš„æè´¨å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
                    input_materials = input_material.split(',')
                    item_materials = item['material'].split(',')

                    # è®¡ç®—æè´¨åŒ¹é…åº¦
                    for in_material in input_materials:
                        for item_material in item_materials:
                            if in_material == item_material:
                                score += 0.1
                                break
                            elif in_material in ['cotton', 'linen', 'jersey'] and item_material in ['cotton', 'linen',
                                                                                                    'jersey']:
                                score += 0.08
                                break
                            elif in_material in ['leather', 'suede'] and item_material in ['leather', 'suede']:
                                score += 0.08
                                break
                            elif in_material in ['wool', 'cashmere', 'silk'] and item_material in ['wool', 'cashmere',
                                                                                                   'silk']:
                                score += 0.08
                                break
                            elif in_material in ['denim'] and item_material in ['cotton', 'jersey']:
                                score += 0.05
                                break
                            elif in_material in ['polyester', 'nylon'] and item_material in ['polyester', 'nylon']:
                                score += 0.05
                                break

                item['match_score'] = score

            # æ‰¾åˆ°æœ€é«˜åˆ†çš„é¡¹ç›®
            if items:  # ç¡®ä¿itemsä¸ä¸ºç©º
                best_item = max(items, key=lambda x: x.get('match_score', x.get('distance', 0)))
                recommendations[category] = best_item
                safe_log_info(
                    f"Best item for {category}: {best_item['image_name']} with score {best_item.get('match_score', 'unknown')}")
            else:
                safe_log_info(f"No valid items for category {category} after scoring")

        except Exception as e:
            safe_log_info(f"Error processing category {category}: {e}")
            safe_log_info(traceback.format_exc())
            continue

    safe_log_info(f"Total recommendations found: {len(recommendations)}")
    return recommendations


def find_most_similar_item_with_attributes(category: str, embedding: np.ndarray) -> Dict:
    if coll is None:
        return {"color": "unknown", "shape": "unknown", "material": "unknown"}
    try:
        embedding = np.asarray(embedding)
        if embedding.dtype != np.float32:
            embedding = embedding.astype(np.float32)
        if embedding.ndim == 1:
            embedding = embedding.reshape(1, -1)  # è½¬ä¸ºäºŒç»´ï¼ŒMilvusæœŸæœ›çš„æ ¼å¼

        safe_category = category.replace("'", "\\'")
        expr = f"category == '{safe_category}'"

        search_results = coll.search(
            data=embedding,
            anns_field='embedding',
            param={"metric_type": "IP", "params": {"nprobe": 128}},
            limit=30,
            expr=expr,
            output_fields=['color', 'shape', 'material'],
            timeout=10.0
        )

        for result in search_results[0]:
            color = getattr(result.entity, 'color', 'unknown')
            shape = getattr(result.entity, 'shape', 'unknown')
            material = getattr(result.entity, 'material', 'unknown')
            if color != 'unknown' or shape != 'unknown' or material != 'unknown':
                return {"color": color, "shape": shape, "material": material}

        if search_results[0]:
            result = search_results[0][0]
            return {
                "color": getattr(result.entity, 'color', 'unknown'),
                "shape": getattr(result.entity, 'shape', 'unknown'),
                "material": getattr(result.entity, 'material', 'unknown')
            }

    except Exception as e:
        safe_log_info(f"Error finding similar item with attributes: {e}")
        safe_log_info(traceback.format_exc())

    return {"color": "unknown", "shape": "unknown", "material": "unknown"}



@app.post("/recommend")
async def recommend_complete_outfit(file: UploadFile = File(...)):
    start_time = time.time()
    try:
        img = Image.open(io.BytesIO(await file.read())).convert('RGB')
        safe_log_info(f"Uploaded image size: {img.size}")

        input_category = detect_clothing_category(img)
        safe_log_info(f"Detected category: {input_category}")

        # é¿å…ä½¿ç”¨GPUå¹¶ä½¿ç”¨è¾ƒä½ç²¾åº¦
        inputs = extractor(images=img, return_tensors='pt')['pixel_values']
        with torch.no_grad():
            # åœ¨ä¸€äº›é‡åŒ–åŠ è½½ä¸‹ï¼Œæ¨¡å‹å¯èƒ½åœ¨ GPU/CPU çš„ä¸åŒä½ç½®ï¼Œç›´æ¥è°ƒç”¨å¹¶æŠŠç»“æœè½¬åˆ° CPU
            emb = vit(pixel_values=inputs).last_hidden_state[:, 0, :].cpu().numpy()

        # ç¡®ä¿å‘é‡ç±»å‹ä¸ºfloat32ä»¥åŒ¹é…Milvusä¸­çš„VECTOR_FLOATç±»å‹
        if emb.dtype != np.float32:
            emb = emb.astype(np.float32)

        # é‡Šæ”¾è¾“å…¥å˜é‡ä»¥èŠ‚çœå†…å­˜
        del inputs
        gc.collect()
        try:
            torch.cuda.empty_cache()
        except Exception:
            pass

        input_attributes = find_most_similar_item_with_attributes(input_category, emb)
        input_color = input_attributes["color"]
        input_shape = input_attributes["shape"]
        input_material = input_attributes["material"]

        # è®°å½•è¾“å…¥å±æ€§
        safe_log_info(f"Input attributes - Color: {input_color}, Shape: {input_shape}, Material: {input_material}")

        recommendations = get_complementary_items(
            input_category, emb, input_color, input_shape, input_material)

        safe_log_info(f"Recommendations received: {recommendations}")

        final_outfit = {}

        # æ–¹æ¡ˆ1ï¼šä¸å†ç­›é€‰ï¼Œç›´æ¥ä½¿ç”¨æ‰€æœ‰æ¨èç»“æœæ„å»ºfinal_outfit
        for category, item in recommendations.items():
            final_outfit[category] = item

        safe_log_info(f"Final outfit: {final_outfit}")

        # æ·»åŠ å®¹é”™å¤„ç†ï¼Œç¡®ä¿å³ä½¿æ²¡æœ‰æ¨èç»“æœä¹Ÿèƒ½ç»§ç»­æ‰§è¡Œ
        if not recommendations and input_category != 'unknown':
            # å¦‚æœæ²¡æœ‰æ¨èç»“æœï¼Œå°è¯•è·å–ä¸€äº›åŸºæœ¬çš„æ¨èé¡¹
            safe_log_info("No recommendations found, attempting to get basic items")
            complementary_categories = get_complementary_categories(input_category)
            if complementary_categories:
                # å°è¯•è·å–ç¬¬ä¸€ä¸ªäº’è¡¥ç±»åˆ«çš„ä¸€äº›åŸºæœ¬é¡¹ç›®
                try:
                    basic_items = search_items_by_category(complementary_categories[0], emb, limit=5)
                    if basic_items:
                        recommendations[complementary_categories[0]] = basic_items[0]
                        final_outfit[complementary_categories[0]] = basic_items[0]
                        safe_log_info(f"Added basic item for fallback: {basic_items[0]}")
                except Exception as e:
                    safe_log_info(f"Error getting basic items: {e}")
                    safe_log_info(traceback.format_exc())
                    # å³ä½¿è·å–åŸºæœ¬é¡¹ç›®å¤±è´¥ï¼Œä¹Ÿè¦ç¡®ä¿èƒ½ç»§ç»­æ‰§è¡Œ
                    pass

        # ä½¿ç”¨0.6Bæ¨¡å‹ç”Ÿæˆè¦ç‚¹
        category_names = {
            'top': 'ä¸Šè¡£',
            'bottom': 'ä¸‹è£…',
            'pants': 'è£¤å­',
            'skirt': 'è£™å­',
            'dress': 'è¿è¡£è£™',
            'outer': 'å¤–å¥—',
            'shoes': 'é‹å­',
            'bag': 'åŒ…è¢‹',
            'belt': 'è…°å¸¦',
            'hat': 'å¸½å­',
            'scarf': 'å›´å·¾',
            'accessories': 'é…é¥°'
        }

        chinese_category = category_names.get(input_category, input_category)

        # æ„å»ºè¾“å‡ºæ ¼å¼
        if final_outfit:
            outline_points = []
            for i, (category, item) in enumerate(final_outfit.items(), 1):
                color = item.get('color', 'unknown')
                shape = item.get('shape', 'unknown')
                material = item.get('material', 'unknown')
                chinese_cat = category_names.get(category, category)
                outline_points.append(f"{i}. æ­é…{chinese_cat}(é¢œè‰²:{color},æ¬¾å¼:{shape},æè´¨:{material})")

            outline_text = "\n".join(outline_points)
        else:
            outline_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ—¶å°šæ­é…å¸ˆï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„å•å“æä¾›3-5æ¡æ ¸å¿ƒæ­é…å»ºè®®ã€‚

                    ç”¨æˆ·å•å“ï¼š{input_color}{chinese_category}

                    è¦æ±‚ï¼š
                    1. æ­é…å»ºè®®åº”è‡ªç„¶æµç•…ï¼Œçªå‡ºæ•´ä½“é€ å‹æ•ˆæœ
                    2. ç»“åˆé¢œè‰²ã€æ¬¾å¼ã€æè´¨ç­‰è¦ç´ ï¼Œä½“ç°é£æ ¼ç‰¹ç‚¹
                    3. å»ºè®®å¯æ¶‰åŠä¸Šè¡£ã€ä¸‹è£…ã€å¤–å¥—ã€é‹åŒ…ã€é…é¥°ç­‰ä¸åŒå“ç±»
                    4. æ¯æ¡å»ºè®®ä¹‹é—´ä¿æŒå¤šæ ·åŒ–
                    5. ä¸è¦è¾“å‡ºé¢å¤–è§£é‡Šæˆ–å…è´£å£°æ˜

                    è¯·ç›´æ¥ç»™å‡ºæ­é…å»ºè®®ï¼š
                    """

            outline_text = generate_outline_local(outline_prompt, max_tokens=500)

            if not outline_text or "é”™è¯¯" in outline_text or "æ— æ³•ç”Ÿæˆ" in outline_text or len(outline_text) < 10:
                outline_text = f"å»ºè®®æ­é…{chinese_category}å¯ä»¥è€ƒè™‘ä»¥ä¸‹å‡ ç§æ–¹å¼ï¼š\n1. é€‰æ‹©ç®€çº¦é£æ ¼çš„é‹å­æ¥å¹³è¡¡æ•´ä½“é€ å‹\n2. æ­é…ä¸€æ¬¾æ—¶å°šçš„åŒ…è¢‹å¢åŠ äº®ç‚¹\n3. æ ¹æ®å­£èŠ‚é€‰æ‹©åˆé€‚çš„å¤–å¥—è¿›è¡Œå ç©¿"

        safe_log_info(f"Generated outline text: {outline_text}")

        # ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡æ–‡æ¡ˆ
        if LLM_API_KEY:
            # æ„é€ ç»™å¤§æ¨¡å‹çš„æç¤ºè¯ï¼Œè®©æ¨¡å‹è¾“å‡ºåŒ…å«ç”¨æˆ·å•å“ä¿¡æ¯å’Œç©¿æ­å»ºè®®
            final_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¶å°šæ­é…å¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆè¯¦ç»†çš„ç©¿æ­å»ºè®®ï¼š

                    ç”¨æˆ·ä¸Šä¼ çš„å•å“ä¿¡æ¯ï¼š
                    - å“ç±»ï¼š{input_category}
                    - é¢œè‰²ï¼š{input_color}
                    - æ¬¾å¼ï¼š{input_shape if input_shape != 'unknown' else 'æœªè¯†åˆ«'}
                    - æè´¨ï¼š{input_material if input_material != 'unknown' else 'æœªè¯†åˆ«'}

                    æ£€ç´¢åˆ°çš„æ¨èæ­é…è¡£å“æˆ–ä¸Šæ¸¸æœ¬åœ°å¤§æ¨¡å‹ç”Ÿæˆçš„æ¨èæ­é…è¦ç‚¹ï¼š
                    {outline_text}

                    æ³¨æ„ä¸Šæ¸¸æ¨¡å‹ç”Ÿäº§å†…å®¹ä¼šæœ‰ä¸€äº›æ— ç”¨ä¿¡æ¯æˆ–é”™è¯¯ä¿¡æ¯ï¼Œè¯·æ­£ç¡®è¯†åˆ«ä¿ç•™æœ‰æ•ˆçš„ä¿¡æ¯ï¼Œä½œä¸ºç©¿æ­è¦ç‚¹ï¼š

                    è¯·ç”¨ä¸­æ–‡æä¾›è¯¦ç»†ä¸”å®ç”¨çš„ç©¿æ­å»ºè®®ï¼Œè¦æ±‚ï¼š
                    1. é¦–å…ˆæè¿°ç”¨æˆ·å•å“çš„ç‰¹ç‚¹å’Œæ­é…ä¼˜åŠ¿
                    2. è¯¦ç»†è¯´æ˜æ¯ä¸ªæ¨èå•å“çš„æ­é…ç†ç”±
                    3. ç»™å‡ºæ•´ä½“æ­é…çš„é£æ ¼æè¿°
                    4. æä¾›é€‚åˆçš„ç©¿ç€åœºæ™¯
                    5. ç»™å‡ºä¸ªæ€§åŒ–è°ƒæ•´å»ºè®®
                    6. æä¾›è´­ä¹°å…³é”®è¯ä»¥ä¾¿ç”¨æˆ·æœç´¢ç±»ä¼¼å•å“

                    è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
                    ğŸ“Œ å•å“åˆ†æ
                    [ç”¨æˆ·å•å“çš„ç‰¹ç‚¹å’Œæ­é…ä¼˜åŠ¿]

                    ğŸ‘— æ­é…å»ºè®®
                    [è¯¦ç»†è¯´æ˜æ¯ä¸ªæ¨èå•å“çš„æ­é…ç†ç”±]

                    ğŸ’„ é£æ ¼å®šä½
                    [æ•´ä½“æ­é…çš„é£æ ¼æè¿°]

                    ğŸ¯ é€‚ç”¨åœºæ™¯
                    [é€‚åˆçš„ç©¿ç€åœºæ™¯]

                    ğŸ¨ ä¸ªæ€§è°ƒæ•´
                    [ä¸ªæ€§åŒ–è°ƒæ•´å»ºè®®]

                    ğŸ›ï¸ è´­ä¹°æŒ‡å—
                    [è´­ä¹°å…³é”®è¯ï¼Œå¸®åŠ©ç”¨æˆ·æœç´¢ç±»ä¼¼å•å“]"""

            outfit_text = call_qwen_api(final_prompt)
        else:
            # å¦‚æœæ²¡æœ‰APIå¯†é’¥ï¼Œç›´æ¥ä½¿ç”¨è¦ç‚¹ä½œä¸ºè¾“å‡º
            outfit_text = f"æ ¸å¿ƒæ­é…è¦ç‚¹ï¼š\n{outline_text}\n\næ³¨æ„ï¼šå¦‚éœ€ç”Ÿæˆè¯¦ç»†æ–‡æ¡ˆï¼Œè¯·é…ç½®å¤§æ¨¡å‹APIå¯†é’¥ã€‚"

        safe_log_info(f"Generated outfit text length: {len(outfit_text)}")
        try:
            safe_log_info(f"Generated outfit text preview: {outfit_text[:500]}...")
        except Exception:
            safe_log_info("Generated outfit text preview: [Contains special characters]")

        end_time = time.time()
        safe_log_info(f"Total processing time: {end_time - start_time:.2f} seconds")

        # ç®€åŒ–è¿”å›ç»“æ„ï¼Œåªè¿”å›ä¸€ä¸ªæ¨¡å‹è¾“å‡º
        return {
            "outfit_description": outfit_text
        }

    except Exception as e:
        safe_log_info(f"Error in recommend_complete_outfit: {e}")
        safe_log_info(traceback.format_exc())
        return {
            "outfit_description": f"å¤„ç†å‡ºé”™: {str(e)}"
        }


@app.get("/health")
async def health_check():
    return {"status": "healthy"}


def main():
    import uvicorn
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        workers=1,
        log_level="info"
    )


if __name__ == "__main__":
    main()
